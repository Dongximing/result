{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aca5bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_imdb.ipynb     cnn_kd_twitter.ipynb      lstm_baseline.ipynb\r\n",
      "bert_twitter.ipynb  cnn_twitter.ipynb         lstm_basline_Twitter.ipynb\r\n",
      "cnn_imdb.ipynb      kd_atten_lstm_imdb.ipynb  lstm_kd_atten_twitter.ipynb\r\n",
      "cnn_kd.ipynb        kd_lstm_imdb.ipynb        lstm_kd_twitter.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b9cb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/6006178/dongxx\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ebaea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16_mercer_kd.out   r_bert_gru.sh       t_atten_lstm_kd.sh\r\n",
      "16_pa_kd.out       r_bert_t.sh         t_att_lstm.sh\r\n",
      "32_mercer_kd.out   \u001b[0m\u001b[38;5;27mresult\u001b[0m/             t_bert_t.sh\r\n",
      "32_pa_kd.out       r_lstm_a.sh         t_cnn_kd.sh\r\n",
      "atten.out          r_lstm.sh           t_cnn.sh\r\n",
      "bert_ft.sh         slurm-21749546.out  Tiwtter_atten_kd.out\r\n",
      "\u001b[38;5;27mdata\u001b[0m/              slurm-21990450.out  Tiwtter_atten.out\r\n",
      "\u001b[38;5;27mdata140\u001b[0m/           slurm-21991185.out  Tiwtter_cnn_kd.out\r\n",
      "\u001b[38;5;27mENV\u001b[0m/               slurm-21992242.out  Tiwtter_cnn.out\r\n",
      "ft_kd_atten.out    slurm-22059655.out  Tiwtter_gru_bert.out\r\n",
      "glove.6B.100d.txt  slurm-22060427.out  Tiwtter_linear.out\r\n",
      "\u001b[38;5;27mIMDB_data\u001b[0m/         slurm-22060432.out  Tiwtter_lstm_kd.out\r\n",
      "\u001b[38;5;27mIMDB_result\u001b[0m/       slurm-22205575.out  Tiwtter_lstm.out\r\n",
      "kd_atten_lstm.out  slurm-22205595.out  t_lstm_kd.sh\r\n",
      "kd_lstm.out        slurm-22290702.out  t_lstm.sh\r\n",
      "\u001b[38;5;27mLSTMbaseline\u001b[0m/      slurm-22290962.out  \u001b[38;5;27mtwitter_baseline\u001b[0m/\r\n",
      "\u001b[38;5;27mModel_parameter\u001b[0m/   slurm-22291353.out  \u001b[38;5;27mtwitter_parameter\u001b[0m/\r\n",
      "new_bert.pt        slurm-22407206.out  \u001b[38;5;27mtwitter_result\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e310ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/6006178/dongxx/LSTMbaseline\n"
     ]
    }
   ],
   "source": [
    "cd LSTMbaseline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b80070a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import CNN_Baseline,LSTMBaseline,LSTM_atten\n",
    "from run_lstm_baseline_classifier import weight_matrix,epoch_time\n",
    "from run_kd_lstm_atten_classifier import validate,generate_batch\n",
    "from run_lstm_baseline_classifier import prepare_dateset\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import GloVe,Vocab,Vectors\n",
    "from tqdm import tqdm\n",
    "from utils import IMDB_indexing, pad_sequenc,pad_sequencing\n",
    "from models import CNN_Baseline,LSTMBaseline\n",
    "import torchtext.vocab\n",
    "import csv\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import config\n",
    "config.seed_torch()\n",
    "from collections import Counter\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd5c4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca1c727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '/home/dongxx/projects/def-parimala/dongxx/data/test.csv'\n",
    "valid = '/home/dongxx/projects/def-parimala/dongxx/data/valid.csv'\n",
    "train ='/home/dongxx/projects/def-parimala/dongxx/data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1638b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load Glove: : 400000it [00:03, 116020.16it/s]\n"
     ]
    }
   ],
   "source": [
    "counter2 = Counter({'<unk>': 400002, '<pad>': 400001})\n",
    "glove = Vectors(name='../glove.6B.100d.txt')\n",
    "f = open('../glove.6B.{}d.txt'.format(100), 'r')\n",
    "loop = tqdm(f)\n",
    "vob = {}\n",
    "loop.set_description('Load Glove')\n",
    "for i,line in enumerate(loop):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vob[word] =400000-i\n",
    "counter1 = copy.deepcopy(vob)\n",
    "f.close()\n",
    "counter1.update(counter2)\n",
    "vocab = Vocab(counter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deba64d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading training data\n",
      "Finish loading training data\n",
      "Start loading validation data\n",
      "Finish loading validation data\n",
      "Start loading testing data\n",
      "Finish loading testing data\n",
      "prepare training and test sets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000lines [00:04, 4675.53lines/s]\n",
      "5000lines [00:01, 4873.59lines/s]\n",
      "25000lines [00:05, 4708.13lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, validation_dataset,test_dataset,labellist = prepare_dateset(train, valid,test,vocab)\n",
    "testing = DataLoader(test_dataset, collate_fn= generate_batch, batch_size=32, shuffle=False)\n",
    "LSTM_model =LSTM_atten(vocab_size = 400002,hidden_dim =256 , n_layers = 2, dropout = 0.25, number_class = 2, bidirectional = True, embedding_dim =100)\n",
    "LSTM_model.embedding_layer.weight.data.copy_(weight_matrix(vocab,glove)).to(device)\n",
    "LSTM_model.embedding_layer.weight.data[1] = torch.zeros(100)\n",
    "LSTM_model.embedding_layer.weight.data[0] = torch.zeros(100)\n",
    "LSTM_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.to(device)\n",
    "LSTM_model.load_state_dict(torch.load('/home/dongxx/projects/def-parimala/dongxx/Model_parameter/kd_atten.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3537aeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32009/1352000694.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflat_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLSTM_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepoch_mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_secs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' | Epoch Time: {epoch_mins}m {epoch_secs}s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6006178/dongxx/LSTMbaseline/run_kd_lstm_atten_classifier.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(validation_dataset, model, criterion, device)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0mtext_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 4)"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "test_loss, test_acc,flat_list = validate(testing,LSTM_model,criterion,device)\n",
    "end_time = time.time()\n",
    "epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "print(f' | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5039a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[item.cpu().numpy() for sublist in flat_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b854cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(labellist, pred_list)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c75149",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labellist, pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011fcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c1a852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
