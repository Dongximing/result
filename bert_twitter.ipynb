{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ea9781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Attention_imdb.ipynb       cnn_kd_twitter.ipynb\r\n",
      " Attention_tiwtter.ipynb    cnn_twitter.ipynb\r\n",
      "'bert_gru_tiwtter .ipynb'   kd_atten_lstm_imdb.ipynb\r\n",
      " bert_imdb.ipynb            kd_lstm_imdb.ipynb\r\n",
      " bert_linear_imdb.ipynb     lstm_baseline.ipynb\r\n",
      " bert_twitter.ipynb         lstm_basline_Twitter.ipynb\r\n",
      " cnn_imdb.ipynb             lstm_kd_atten_twitter.ipynb\r\n",
      " cnn_kd.ipynb               lstm_kd_twitter.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47d4ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/6006178/dongxx\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3fdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/6006178/dongxx/twitter_baseline\n"
     ]
    }
   ],
   "source": [
    "cd twitter_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e286bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_train import validate, prepare_dateset,generate_batch,epoch_time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from models import BERTGRUSentiment\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import GloVe,Vocab,Vectors\n",
    "from tqdm import tqdm\n",
    "from utils import Twitter_indexing, pad_sequenc,pad_sequencing\n",
    "from models import CNN_Baseline,LSTMBaseline\n",
    "import torchtext.vocab\n",
    "import csv\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import config\n",
    "config.seed_torch()\n",
    "from collections import Counter\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7025af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel,BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8064482",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7626fd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=2,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a077935",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '/home/dongxx/projects/def-parimala/dongxx/data140/test.csv'\n",
    "valid = '/home/dongxx/projects/def-parimala/dongxx/data140/valid.csv'\n",
    "train ='/home/dongxx/projects/def-parimala/dongxx/data140/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca42458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading training data\n",
      "Finish loading training data\n",
      "Start loading validation data\n",
      "Finish loading validation data\n",
      "Start loading testing data\n",
      "Finish loading testing data\n",
      "prepare training and test sets\n"
     ]
    }
   ],
   "source": [
    "train_dataset, validation_dataset,test_dataset,labellist  = prepare_dateset(train, valid,test)\n",
    "testing = DataLoader(test_dataset, collate_fn= generate_batch, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a46c4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Epoch Time: 5m 32s\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.load_state_dict(torch.load(config.BERT_Tiwtter_PATH))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.to(device)\n",
    "start_time = time.time()\n",
    "test_loss, test_acc,flat_list = validate(testing, model, criterion, device)\n",
    "end_time = time.time()\n",
    "epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "print(f' | Epoch Time: {epoch_mins}m {epoch_secs}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc40ed58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.299 | Test Acc: 87.66%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[item.cpu().numpy() for sublist in flat_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a3a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[item.cpu().numpy() for sublist in flat_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bec8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(labellist, pred_list)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19549f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labellist, pred_list,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe96fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
